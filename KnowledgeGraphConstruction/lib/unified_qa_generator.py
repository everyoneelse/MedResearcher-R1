#!/usr/bin/env python3
"""
ç»Ÿä¸€QAç”Ÿæˆå™¨
å°†ä¿¡æ¯æ¨¡ç³ŠåŒ–å’Œé—®é¢˜ç”Ÿæˆæ•´åˆä¸ºä¸€ä¸ªå¼ºå¤§çš„LLMæŒ‡ä»¤åŒ…
æ”¯æŒä¸¤ç§æ¨¡ç³ŠåŒ–èŒƒå¼ï¼šæ¦‚å¿µæœ¬èº«æ¨¡ç³ŠåŒ–å’Œå±æ€§æŒ‡ä»£æ¨¡ç³ŠåŒ–
"""

import logging
import json
import random
from typing import Dict, List, Any, Optional
import openai
from config import settings

logger = logging.getLogger(__name__)

class UnifiedQAGenerator:
    """ç»Ÿä¸€çš„æ¨¡ç³ŠåŒ–+QAç”Ÿæˆå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        # å¸¸è§„LLMå®¢æˆ·ç«¯ï¼ˆç”¨äºä¸€èˆ¬å¤„ç†ï¼‰
        self.client = openai.AsyncOpenAI(
            api_key=settings.OPENAI_API_KEY,
            base_url=settings.OPENAI_API_BASE
        )
        
        # QAä¸“ç”¨æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆç”¨äºæœ€ç»ˆé—®é¢˜ç”Ÿæˆï¼‰
        self.qa_client = openai.AsyncOpenAI(
            api_key=settings.QA_API_KEY,
            base_url=settings.QA_API_BASE
        )
        
        logger.info(f"åˆå§‹åŒ–QAä¸“ç”¨æ¨¡å‹: {settings.QA_MODEL} @ {settings.QA_API_BASE}")
        
        # æ·±åº¦æ¨¡ç³ŠåŒ–èŒƒå¼é…ç½®
        self.obfuscation_config = {
            'deep_concept_obfuscation_examples': {
                'extreme_time': {
                    'original': '1985å¹´3æœˆ15æ—¥',
                    'obfuscated': 'å†·æˆ˜åæœŸæŸä¸ªæ˜¥å­£ï¼Œå½“æ—¶æ­£å€¼æŸä¸ªåå¹´æœŸçš„ä¸­æ®µ'
                },
                'deep_number': {
                    'original': '45,000äºº',
                    'obfuscated': 'è§„æ¨¡ä»‹äºæŸä¸ªå¤§å‹ä½“è‚²åœºå®¹é‡ä¸å°å‹åŸå¸‚äººå£ä¹‹é—´çš„ç¾¤ä½“'
                },
                'multi_organization': {
                    'original': 'æ–¯å¦ç¦å¤§å­¦',
                    'obfuscated': 'ä½äºè¥¿æµ·å²¸ç¡…è°·æ ¸å¿ƒåŒºåŸŸçš„ä¸€æ‰€ä»¥åˆ›æ–°é—»åçš„ç§ç«‹ç ”ç©¶æœºæ„'
                }
            },
            'attribute_obfuscation_examples': {
                'location': {
                    'entity': 'è‹è½¼',
                    'attribute': 'å››å·çœ‰å±±',
                    'obfuscated': 'ä¸€ä½å‡ºç”Ÿäºèœ€åœ°çš„æ–‡å­¦å®¶'
                },
                'time': {
                    'entity': 'çˆ±å› æ–¯å¦',
                    'attribute': '1879å¹´å‡ºç”Ÿ',
                    'obfuscated': 'ä¸€ä½19ä¸–çºªæœ«å‡ºç”Ÿçš„ç‰©ç†å­¦å®¶'
                },
                'profession': {
                    'entity': 'è´å¤šèŠ¬',
                    'attribute': 'ä½œæ›²å®¶',
                    'obfuscated': 'ä¸€ä½ä»¥éŸ³ä¹åˆ›ä½œé—»åçš„è‰ºæœ¯å®¶'
                }
            },
            'quantitative_reasoning_examples': {
                'numerical_range': {
                    'original': 'å‘è¡Œäº†2000ä¸‡ä»½',
                    'obfuscated': 'é”€é‡çªç ´äº†æŸä¸ªé‡Œç¨‹ç¢‘æ•°å­—ï¼Œè¶…è¿‡äº†1000ä¸‡ä½†å°‘äº5000ä¸‡'
                },
                'chronological_logic': {
                    'original': '2024å¹´8æœˆ20æ—¥å‘å¸ƒ',
                    'obfuscated': 'åœ¨ç–«æƒ…åçš„ç¬¬å››å¹´ã€æŸä¸ªå¤å­£æœˆä»½çš„ä¸‹æ—¬å‘å¸ƒ'
                },
                'comparative_quantity': {
                    'original': 'ç”¨æ—¶3å¹´å¼€å‘',
                    'obfuscated': 'å¼€å‘å‘¨æœŸæ¯”å¤§å¤šæ•°åŒç±»äº§å“æ›´é•¿ï¼Œä½†å°‘äºä¸€ä¸ªå¥¥è¿å‘¨æœŸ'
                },
                'conditional_logic': {
                    'original': 'è·å¾—äº†å¤šä¸ªå¥–é¡¹',
                    'obfuscated': 'å¦‚æœä»¥è·å¥–æ•°é‡è¡¡é‡ï¼Œè¯¥é¡¹ç›®åœ¨åŒæœŸå‘å¸ƒçš„ä½œå“ä¸­æ’åå‰åˆ—'
                }
            }
        }
    
    async def generate_qa(
        self, 
        sample_info: Dict[str, Any],
        target_entity_for_answer: Optional[str] = None,
        sampling_algorithm: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ç»Ÿä¸€ç”Ÿæˆï¼šæ¨¡ç³ŠåŒ–å¤„ç† + å¤æ‚é—®é¢˜æ„å»º
        
        Args:
            sample_info: é‡‡æ ·çš„å­å›¾ä¿¡æ¯
            target_entity_for_answer: æŒ‡å®šä½œä¸ºç­”æ¡ˆçš„ç›®æ ‡å®ä½“ï¼ˆå¯é€‰ï¼Œç°åœ¨ä¸»è¦ç”¨äºå…¼å®¹æ€§ï¼‰
            
        Returns:
            åŒ…å«é—®é¢˜ã€ç­”æ¡ˆã€æ¨ç†è¿‡ç¨‹çš„å®Œæ•´ç»“æœ
        """
        # ç»§æ‰¿trace contextï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        from .trace_manager import TraceManager, start_trace
        parent_trace = TraceManager.get_trace_id()
        if parent_trace:
            logger.info(f"UnifiedQAç»§æ‰¿trace: {parent_trace}")
        else:
            start_trace(prefix="unified_qa")
            logger.info(f"UnifiedQAåˆ›å»ºæ–°trace")
        
        try:
            nodes = sample_info.get('nodes', [])
            relations = sample_info.get('relations', [])
            
            if not nodes or not relations:
                logger.warning("å­å›¾ä¿¡æ¯ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆå¤æ‚QA")
                return await self._generate_fallback_qa()
            
            # æ„å»ºå­å›¾ä¿¡æ¯JSON
            subgraph_json = self._build_subgraph_json(nodes, relations, sampling_algorithm)
            
            # ä½¿ç”¨æ™ºèƒ½ç­”æ¡ˆé€‰æ‹©æ¨¡å¼ï¼šè®©OpenRouteræ¨¡å‹è‡ªä¸»é€‰æ‹©æœ€ä½³ç­”æ¡ˆ
            # å¦‚æœæ²¡æœ‰æŒ‡å®štarget_entity_for_answerï¼Œåˆ™ä¼ å…¥ç©ºå­—ç¬¦ä¸²è®©æ¨¡å‹è‡ªå·±é€‰æ‹©
            placeholder_answer = target_entity_for_answer or "å¾…æ™ºèƒ½é€‰æ‹©"
            
            logger.info("ä½¿ç”¨æ™ºèƒ½ç­”æ¡ˆé€‰æ‹©æ¨¡å¼ï¼šè®©OpenRouteræ¨¡å‹è‡ªä¸»é€‰æ‹©æœ€ä½³ç­”æ¡ˆå®ä½“")
            
            # ç”Ÿæˆå®Œæ•´çš„QAæŒ‡ä»¤åŒ…
            qa_prompt = self._build_master_prompt(subgraph_json, placeholder_answer)
            
            # æ‰§è¡Œç»Ÿä¸€ç”Ÿæˆ
            logger.info(f"ä½¿ç”¨QAä¸“ç”¨æ¨¡å‹ç”Ÿæˆé—®é¢˜: {settings.QA_MODEL}")
            response = await self._generate_response(qa_prompt)
            if not response:
                return {}
            # è§£æå’ŒéªŒè¯ç»“æœ
            qa_result = self._parse_and_validate_response(response, nodes, placeholder_answer)
            
            # å¦‚æœæ¨¡å‹é€‰æ‹©äº†æ–°çš„ç­”æ¡ˆï¼Œä½¿ç”¨æ™ºèƒ½é€‰æ‹©çš„ç­”æ¡ˆ
            selected_answer = qa_result.get('answer', '')
            if selected_answer and selected_answer != placeholder_answer:
                logger.info(f"OpenRouteræ¨¡å‹æ™ºèƒ½é€‰æ‹©çš„ç­”æ¡ˆ: {selected_answer}")
                # ç¡®ä¿answerå­—æ®µä¸selected_answerä¸€è‡´
                qa_result['answer'] = selected_answer
                logger.info("ä½¿ç”¨OpenRouteræ¨¡å‹æ™ºèƒ½é€‰æ‹©çš„ç­”æ¡ˆ")
            else:
                logger.info(f"ä½¿ç”¨é»˜è®¤/é¢„è®¾ç­”æ¡ˆ: {qa_result.get('answer', '')}")
            
            # è®°å½•æœ€ç»ˆQAç»“æœ
            final_question = qa_result.get('question', '')
            final_answer = qa_result.get('answer', '')
            logger.info(f"æœ€ç»ˆç”Ÿæˆç»“æœ: é—®é¢˜é•¿åº¦={len(final_question)}, ç­”æ¡ˆ={final_answer}")
            
            return qa_result
            
        except Exception as e:
            logger.error(f"ç»Ÿä¸€QAç”Ÿæˆå¤±è´¥: {e}")
            return await self._generate_fallback_qa()
    
    def _build_subgraph_json(self, nodes: List[Dict], relations: List[Dict], sampling_algorithm: Optional[str] = None) -> str:
        """æ„å»ºç»“æ„åŒ–çš„å­å›¾ä¿¡æ¯JSON"""
        # æ„å»ºå®ä½“åˆ—è¡¨
        entities_info = []
        for i, node in enumerate(nodes):
            entity_info = {
                'id': f'entity_{i+1}',
                'name': node.get('name', f'å®ä½“{i+1}'),
                'type': node.get('type', 'unknown'),
                'description': node.get('description', ''),
                'attributes': node.get('attributes', {}),
                'original_name': node.get('original_name', node.get('name', ''))
            }
            entities_info.append(entity_info)
        
        # æ„å»ºå…³ç³»åˆ—è¡¨
        relations_info = []
        for i, rel in enumerate(relations):
            relation_info = {
                'id': f'relation_{i+1}',
                'source': rel.get('source') or rel.get('head') or rel.get('from'),
                'target': rel.get('target') or rel.get('tail') or rel.get('to'),
                'type': rel.get('type') or rel.get('relation') or 'related_to',
                'description': rel.get('description', ''),
                'weight': rel.get('weight', 1.0)
            }
            relations_info.append(relation_info)
        
        # æ„å»ºå®Œæ•´çš„å­å›¾JSON
        subgraph_data = {
            'entities': entities_info,
            'relations': relations_info,
            'graph_stats': {
                'total_entities': len(entities_info),
                'total_relations': len(relations_info),
                'sampling_algorithm': sampling_algorithm or (nodes[0].get('sampling_algorithm', 'unknown') if nodes else 'unknown')
            }
        }
        
        return json.dumps(subgraph_data, ensure_ascii=False, indent=2)
    
    def _select_answer_target(self, nodes: List[Dict]) -> str:
        """æ™ºèƒ½é€‰æ‹©ç­”æ¡ˆç›®æ ‡å®ä½“ï¼ˆä¼˜å…ˆé€‰æ‹©ç®€å•æ˜ç¡®çš„å®ä½“ï¼‰"""
        candidates = []
        
        for node in nodes:
            name = node.get('name', '')
            original_name = node.get('original_name', name)
            entity_type = node.get('type', '').lower()
            attributes = node.get('attributes', {})
            description = node.get('description', '')
            
            # è®¡ç®—å®ä½“çš„"ç®€æ´æ€§å¾—åˆ†"ï¼ˆåç§°è¶ŠçŸ­è¶Šå¥½ï¼‰
            name_length = len(name)
            word_count = len(name.split())
            
            # è®¡ç®—å®ä½“ç±»å‹ä¼˜å…ˆçº§
            type_priority = self._get_type_priority(entity_type)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯äº‹ä»¶ç±»å®ä½“ï¼ˆé€šå¸¸åŒ…å«è¾ƒé•¿æè¿°æ€§åç§°ï¼‰
            is_event_like = any(keyword in name.lower() for keyword in [
                'å‘å¸ƒ', 'å‘è¡Œ', 'å¯åŠ¨', 'ä¸¾åŠ', 'çªç ´', 'æ¼”ç¤º', 'é¢„å‘Š', 'è´ºå²', 'çŸ­ç‰‡',
                'è¯•ç©', 'é”€é‡', 'å¼€å‘', 'é¦–å‘', 'è™šå¹»å¼•æ“', 'å‰§æƒ…', 'çº¿ä¸‹'
            ]) or entity_type == 'event'
            
            # ç®€æ´æ€§å¾—åˆ†ï¼šè¶Šç®€æ´åˆ†æ•°è¶Šé«˜
            simplicity_score = 100 - name_length - (word_count * 5)
            if is_event_like:
                simplicity_score -= 50  # äº‹ä»¶ç±»å®ä½“å¤§å¹…é™ä½å¾—åˆ†
            
            candidates.append({
                'name': original_name or name,
                'simplicity_score': simplicity_score,
                'type_priority': type_priority,
                'is_event_like': is_event_like,
                'has_original': bool(original_name and original_name != name),
                'entity_type': entity_type
            })
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼šç±»å‹ä¼˜å…ˆçº§ > ç®€æ´æ€§å¾—åˆ† > æœ‰åŸå§‹åç§°
        candidates.sort(
            key=lambda x: (x['type_priority'], x['simplicity_score'], x['has_original']), 
            reverse=True
        )
        
        logger.info(f"é€‰æ‹©ç­”æ¡ˆç›®æ ‡å®ä½“: {candidates[0]['name']} (ç±»å‹: {candidates[0]['entity_type']}, ç®€æ´æ€§: {candidates[0]['simplicity_score']}, äº‹ä»¶ç±»: {candidates[0]['is_event_like']})")
        
        return candidates[0]['name'] if candidates else nodes[0].get('name', 'æœªçŸ¥å®ä½“')
    
    def _get_type_priority(self, entity_type: str) -> int:
        """è·å–å®ä½“ç±»å‹çš„ä¼˜å…ˆçº§ï¼ˆè¶Šé«˜è¶Šé€‚åˆä½œä¸ºç­”æ¡ˆï¼‰"""
        priority_map = {
            'person': 100,       # äººç‰© - æœ€é€‚åˆ
            'organization': 95,  # ç»„ç»‡
            'location': 90,      # åœ°ç‚¹
            'technology': 85,    # æŠ€æœ¯äº§å“
            'concept': 80,       # æ¦‚å¿µ
            'time': 60,         # æ—¶é—´ - ä¸å¤ªé€‚åˆ
            'event': 30,        # äº‹ä»¶ - æœ€ä¸é€‚åˆ
            'unknown': 50       # æœªçŸ¥ç±»å‹
        }
        return priority_map.get(entity_type.lower(), 50)
    
    def _build_master_prompt(self, subgraph_json: str, target_answer: str) -> str:
        """æ„å»ºä¸»æ§QAç”ŸæˆæŒ‡ä»¤åŒ…"""
        
        # æ£€æµ‹é‡‡æ ·ç®—æ³•ç±»å‹
        import json
        try:
            subgraph_data = json.loads(subgraph_json)
            sampling_algorithm = subgraph_data.get('graph_stats', {}).get('sampling_algorithm', 'unknown')
        except:
            sampling_algorithm = 'unknown'
        
        # é’ˆå¯¹æœ€é•¿é“¾é‡‡æ ·ç®—æ³•çš„ç‰¹æ®Šè¦æ±‚
        max_chain_requirement = ""
        if sampling_algorithm == 'max_chain':
            max_chain_requirement = f"""
### ğŸ”— **æœ€é•¿é“¾é‡‡æ ·ç‰¹æ®Šè¦æ±‚ (MAX CHAIN SAMPLING)**

ç”±äºå­å›¾ä½¿ç”¨äº†æœ€é•¿é“¾é‡‡æ ·ç®—æ³•ï¼Œä½ å¿…é¡»ï¼š
1. **è¯†åˆ«å¹¶åˆ©ç”¨æœ€é•¿çš„é€»è¾‘é“¾æ¡**ï¼šæ‰¾åˆ°å­å›¾ä¸­æœ€é•¿çš„å®ä½“å…³ç³»é“¾ï¼ˆè‡³å°‘4-5ä¸ªå®ä½“çš„è¿ç»­å…³ç³»ï¼‰
2. **æ„å»ºé“¾å¼æ¨ç†é—®é¢˜**ï¼šé—®é¢˜å¿…é¡»å¼ºåˆ¶è¦æ±‚æ²¿ç€è¿™æ¡é•¿é“¾è¿›è¡Œé€æ­¥æ¨ç†
3. **å¢å¼ºæ¨ç†å¤æ‚åº¦**ï¼šæ¯ä¸€æ­¥æ¨ç†éƒ½éœ€è¦ä»å‰ä¸€æ­¥çš„ç»“æœæ¨å¯¼ä¸‹ä¸€æ­¥ï¼Œå½¢æˆä¸¥å¯†çš„é€»è¾‘é“¾æ¡
4. **å¤šå±‚æ¨¡ç³ŠåŒ–**ï¼šå¯¹é“¾æ¡ä¸Šçš„æ¯ä¸ªå®ä½“éƒ½è¿›è¡Œä¸åŒç¨‹åº¦çš„æ¨¡ç³ŠåŒ–ï¼Œå¢åŠ è¯†åˆ«éš¾åº¦
5. **æœ€ç»ˆæ”¶æ•›**ï¼šç»è¿‡é•¿é“¾æ¨ç†æœ€ç»ˆå¿…é¡»ç²¾ç¡®æŒ‡å‘ä½ æ™ºèƒ½é€‰æ‹©çš„æœ€ä½³ç­”æ¡ˆå®ä½“

**é“¾å¼æ¨ç†æ¨¡å¼ç¤ºä¾‹ï¼š**
"é€šè¿‡å®ä½“Açš„å±æ€§X â†’ è¯†åˆ«å…³è”å®ä½“B â†’ åŸºäºBçš„ç‰¹å¾Y â†’ è¿½è¸ªåˆ°å®ä½“C â†’ ç»“åˆCçš„å…³ç³»Z â†’ æœ€ç»ˆå®šä½å®ä½“D"

---
"""
        
        prompt = f"""# ä»»åŠ¡ï¼šåŸºäºå­å›¾ç”Ÿæˆå¤šè·³æ¨ç†é—®é¢˜

ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®é¢˜ç”Ÿæˆå™¨ï¼Œéœ€è¦æ ¹æ®æä¾›çš„å­å›¾ä¿¡æ¯ç”Ÿæˆä¸€ä¸ªéœ€è¦å¤šè·³æ¨ç†çš„é—®é¢˜ã€‚

## å­å›¾ä¿¡æ¯
```json
{subgraph_json}
```

## ç”Ÿæˆè¦æ±‚

1. **é€‰æ‹©ç­”æ¡ˆå®ä½“**ï¼šä»å­å›¾ä¸­æ™ºèƒ½é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„å®ä½“ä½œä¸ºç­”æ¡ˆï¼Œç­”æ¡ˆå¿…é¡»æ˜¯æ˜ç¡®æ— æ­§ä¹‰çš„ä¿¡æ¯
2. **æ¨¡ç³ŠåŒ–æè¿°**ï¼šå¯¹å®ä½“è¿›è¡Œé€‚åº¦æ¨¡ç³ŠåŒ–ï¼Œä¸ç›´æ¥ä½¿ç”¨å®ä½“åç§°
3. **å¤šè·³æ¨ç†**ï¼šæ„å»ºéœ€è¦å¤šæ­¥æ¨ç†çš„é—®é¢˜
4. **æ¨ç†è·¯å¾„**ï¼šç”Ÿæˆè§£ç­”é—®é¢˜çš„å®Œæ•´æ¨ç†ã€æŸ¥è¯¢è·¯å¾„ï¼Œä½¿ç”¨å‚æ•°åä»£æ›¿å®é™…ä¿¡æ¯

## æ¨ç†è·¯å¾„è¦æ±‚

reasoning_pathå¿…é¡»è¯¦ç»†æè¿°å¦‚ä½•ä¸€æ­¥æ­¥è§£ç­”é—®é¢˜ï¼ŒåŒ…æ‹¬ï¼š
- **æ¨ç†æ­¥éª¤**ï¼šè¯´æ˜æ¯ä¸€æ­¥çš„é€»è¾‘æ¨å¯¼è¿‡ç¨‹
- **æŸ¥è¯¢éœ€æ±‚**ï¼šæŒ‡å‡ºéœ€è¦æŸ¥æ‰¾å“ªäº›å¤–éƒ¨ä¿¡æ¯æ¥éªŒè¯æ¨ç†
- **ä¿¡æ¯å…³è”**ï¼šè§£é‡Šå¦‚ä½•å°†ä¸åŒçº¿ç´¢ç»„åˆèµ·æ¥
- **æœ€ç»ˆæ”¶æ•›**ï¼šè¯´æ˜å¦‚ä½•ä»å¤šæ¡çº¿ç´¢æœ€ç»ˆç¡®å®šå”¯ä¸€ç­”æ¡ˆ

**ã€é‡è¦ã€‘å‚æ•°åŒ–è¡¨è¾¾è¦æ±‚**ï¼š
- **ä¸¥ç¦å‡ºç°ä»»ä½•å®é™…ä¿¡æ¯**ï¼šåŒ…æ‹¬å®ä½“åç§°ã€å…·ä½“æ•°æ®ã€æ—¶é—´ä¿¡æ¯ã€äººåã€åœ°åç­‰
- **å¿…é¡»ä½¿ç”¨å‚æ•°å**ï¼šEntity_Aã€Entity_Bã€Target_Entityã€Clue_1ã€Clue_2ã€Data_Xç­‰
- **å®Œå…¨å‚æ•°åŒ–**ï¼šreasoning_pathä¸­çš„æ¯ä¸€ä¸ªå…·ä½“ä¿¡æ¯éƒ½å¿…é¡»ç”¨å¯¹åº”çš„å‚æ•°åä»£æ›¿
- **ç¤ºä¾‹**ï¼šå†™æˆ"é€šè¿‡Entity_Açš„Attribute_1ç‰¹å¾ï¼ŒæŸ¥è¯¢Data_Xä¿¡æ¯ï¼Œå…³è”åˆ°Entity_B"ï¼Œè€Œä¸æ˜¯"é€šè¿‡ç³–å°¿ç—…çš„ç—‡çŠ¶ç‰¹å¾ï¼ŒæŸ¥è¯¢è¡€ç³–æ•°æ®ï¼Œå…³è”åˆ°èƒ°å²›ç´ "

## ç­”æ¡ˆé€‰æ‹©æ ‡å‡†

- **æ˜ç¡®æ€§**ï¼šç­”æ¡ˆå¿…é¡»æ˜¯å…·ä½“ã€æ˜ç¡®çš„å®ä½“åç§°ï¼Œé¿å…æ¨¡ç³Šæˆ–æ­§ä¹‰çš„æ¦‚å¿µ
- **å”¯ä¸€æ€§**ï¼šç­”æ¡ˆåœ¨ç»™å®šå­å›¾ä¸­å¿…é¡»æ˜¯å”¯ä¸€ç¡®å®šçš„ï¼Œä¸ä¼šä¸å…¶ä»–å®ä½“æ··æ·†
- **å…·ä½“æ€§**ï¼šä¼˜å…ˆé€‰æ‹©å…·ä½“çš„å®ä½“ï¼ˆå¦‚äººåã€è¯ç‰©åã€ç–¾ç—…åï¼‰è€ŒéæŠ½è±¡æ¦‚å¿µ

## æ¨¡ç³ŠåŒ–ç­–ç•¥

- **æ—¶é—´æ¨¡ç³ŠåŒ–**ï¼š"2019å¹´" â†’ "æŸä¸ªä»¥9ç»“å°¾çš„å¹´ä»½"
- **æœºæ„æ¨¡ç³ŠåŒ–**ï¼š"æ¸…åå¤§å­¦" â†’ "ä½äºåŒ—äº¬çš„çŸ¥åç†å·¥ç§‘å¤§å­¦"  
- **äººç‰©æ¨¡ç³ŠåŒ–**ï¼š"å¼ ä¸‰æ•™æˆ" â†’ "æŸä½åœ¨è¯¥é¢†åŸŸæœ‰é‡è¦è´¡çŒ®çš„å­¦è€…"
- **æ•°å€¼æ¨¡ç³ŠåŒ–**ï¼š"50ä¸‡äºº" â†’ "è§„æ¨¡çº¦ä¸ºä¸­ç­‰åŸå¸‚äººå£çš„ç¾¤ä½“"

## è¾“å‡ºæ ¼å¼

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

```json
{{
    "question": "ç”Ÿæˆçš„å¤šè·³æ¨ç†é—®é¢˜ï¼ˆä½¿ç”¨æ¨¡ç³ŠåŒ–æè¿°ï¼‰",
    "answer": "é€‰æ‹©çš„å®ä½“åç§°",
    "reasoning_path": "è¯¦ç»†çš„è§£ç­”æ­¥éª¤ï¼ŒåŒ…æ‹¬æ¨ç†è¿‡ç¨‹ã€æŸ¥è¯¢éœ€æ±‚ã€ä¿¡æ¯å…³è”ç­‰ï¼ˆä¸¥ç¦å‡ºç°ä»»ä½•å®é™…ä¿¡æ¯ï¼Œå¿…é¡»å…¨éƒ¨ä½¿ç”¨Entity_Aã€Entity_Bã€Clue_1ç­‰å‚æ•°åï¼‰",
    "entity_mapping": {{
        "Entity_A": "ç¬¬ä¸€ä¸ªç›¸å…³å®ä½“çš„å®é™…åç§°",
        "Entity_B": "ç¬¬äºŒä¸ªç›¸å…³å®ä½“çš„å®é™…åç§°",
        "Target_Entity": "ç­”æ¡ˆå®ä½“çš„å®é™…åç§°",
        "Clue_1": "ç¬¬ä¸€ä¸ªçº¿ç´¢çš„å®é™…å†…å®¹"
    }}
}}
```

è¯·ç”Ÿæˆä¸€ä¸ªæ¸…æ™°ã€æœ‰é€»è¾‘çš„å¤šè·³æ¨ç†é—®é¢˜ã€‚

**é‡è¦æé†’**ï¼š
- ç­”æ¡ˆå¿…é¡»æ˜¯å­å›¾ä¸­æ˜ç¡®æ— æ­§ä¹‰çš„å®ä½“åç§°ï¼Œä¸èƒ½æ˜¯æ¨¡ç³Šæ¦‚å¿µæˆ–æè¿°æ€§å†…å®¹
- reasoning_pathå¿…é¡»æä¾›å®Œæ•´çš„è§£ç­”è·¯å¾„ï¼ŒåŒ…æ‹¬æ¯ä¸€æ­¥æ¨ç†ã€éœ€è¦æŸ¥è¯¢çš„ä¿¡æ¯ã€å¦‚ä½•å…³è”çº¿ç´¢ç­‰è¯¦ç»†æ­¥éª¤
- **reasoning_pathä¸¥ç¦å‡ºç°ä»»ä½•å®é™…ä¿¡æ¯**ï¼šä¸èƒ½æœ‰å®ä½“åç§°ã€å…·ä½“æ•°æ®ã€äººåã€åœ°åç­‰ï¼Œå¿…é¡»å…¨éƒ¨ç”¨å‚æ•°åï¼ˆEntity_Aã€Clue_1ç­‰ï¼‰ä»£æ›¿"""

        return prompt
    
    async def _generate_response(self, prompt: str) -> str:
        """ç”ŸæˆLLMå“åº” - ä½¿ç”¨QAä¸“ç”¨æ¨¡å‹"""
        max_retries = 3
        for attempt in range(max_retries):
            try:
                logger.info(f"OpenRouter APIè°ƒç”¨ (å°è¯• {attempt + 1}/{max_retries})")
                
                # ä½¿ç”¨QAä¸“ç”¨æ¨¡å‹å®¢æˆ·ç«¯
                response = await self.qa_client.chat.completions.create(
                    model=settings.QA_MODEL,
                    messages=[
                        {
                            "role": "system", 
                            "content": "ä½ æ˜¯ä¸€ä½é—®é¢˜è®¾è®¡ä¸“å®¶ï¼Œä¸“ç²¾äºæ„å»ºéœ€è¦å¤šæ­¥æ¨ç†çš„å¤æ‚é—®é¢˜ã€‚ä½ ç²¾é€šä¿¡æ¯æ¨¡ç³ŠåŒ–æŠ€æœ¯å’Œå¹²æ‰°è®¾è®¡ï¼Œèƒ½å¤Ÿå°†ç®€å•ç›´æ¥çš„ä¿¡æ¯è½¬åŒ–ä¸ºéœ€è¦å¤æ‚çš„é€»è¾‘æ¨ç†+å¤šé‡ä¿¡æ¯æŸ¥è¯æ‰èƒ½è§£å†³çš„è°œé¢˜ã€‚ä½ çš„é—®é¢˜è®¾è®¡åŸåˆ™æ˜¯ï¼šæœ€å¤§åŒ–æ¨ç†æ­¥éª¤æ•°é‡ï¼Œæœ€å¤§åŒ–ä¿¡æ¯æŸ¥æ‰¾ä¾èµ–ï¼Œæœ€å°åŒ–ç›´æ¥çº¿ç´¢ï¼Œç¡®ä¿ç­”æ¡ˆçš„å”¯ä¸€æ€§å’Œå¼ºéªŒè¯æ€§ã€‚"
                        },
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.9,  # æ›´é«˜çš„æ¸©åº¦ä»¥å¢åŠ åˆ›é€ æ€§å’Œå¤æ‚åº¦
                    max_tokens=8192,  # å¤§å¹…å¢åŠ tokené™åˆ¶ï¼Œæ”¯æŒè¶…å¤æ‚é—®é¢˜ç”Ÿæˆ
                    stream=False,  # ç¡®ä¿ä¸ä½¿ç”¨æµå¼è¾“å‡º
                    top_p=0.85,  # é€‚å½“é™ä½top_på¢åŠ å¤šæ ·æ€§
                    presence_penalty=0.2,  # å¢åŠ é¿å…é‡å¤çš„åŠ›åº¦
                    frequency_penalty=0.15,  # æ›´å¼ºé¼“åŠ±å¤šæ ·æ€§å’Œåˆ›æ–°è¡¨è¾¾
                    timeout=120  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°2åˆ†é’Ÿ
                )
                
                # è®°å½•APIå“åº”è¯¦æƒ…
                logger.info(f"OpenRouter APIå“åº”æˆåŠŸ:")
                logger.info(f"  - Model: {response.model if hasattr(response, 'model') else 'N/A'}")
                logger.info(f"  - Usage: {response.usage if hasattr(response, 'usage') else 'N/A'}")
                
                # æå–å†…å®¹ï¼Œå…¼å®¹openrouterçš„è¿”å›æ ¼å¼
                content = response.choices[0].message.content
                if not content:
                    logger.warning(f"å°è¯• {attempt + 1}: å“åº”å†…å®¹ä¸ºç©º")
                    if attempt < max_retries - 1:
                        continue
                    return ""
                
                content = content.strip()
                logger.info(f"åŸå§‹å“åº”é•¿åº¦: {len(content)} å­—ç¬¦")
            
                # æˆªå–</think>åçš„éƒ¨åˆ†ä½œä¸ºçœŸæ­£çš„å“åº”å†…å®¹
                if '</think>' in content:
                    think_end_index = content.find('</think>')
                    content = content[think_end_index + len('</think>'):].strip()
                    logger.info("æ£€æµ‹åˆ°</think>æ ‡è®°ï¼Œæˆªå–åç»­å†…å®¹ä½œä¸ºå“åº”")
                
                # æ£€æŸ¥å“åº”å®Œæ•´æ€§
                if not self._is_response_complete(content):
                    logger.warning(f"å°è¯• {attempt + 1}: å“åº”ä¸å®Œæ•´ (é•¿åº¦: {len(content)})")
                    logger.warning(f"å“åº”æœ«å°¾: ...{content[-100:] if len(content) > 100 else content}")
                    logger.info(f"ä¸å®Œæ•´å“åº”:\n{content}")
                    if attempt < max_retries - 1:
                        logger.info(f"é‡è¯•è·å–å®Œæ•´å“åº”...")
                        continue
                    else:
                        logger.error("å¤šæ¬¡å°è¯•åä»è·å¾—ä¸å®Œæ•´å“åº”ï¼Œä½¿ç”¨å½“å‰å“åº”")
                
                return content
                
            except Exception as e:
                logger.error(f"OpenRouter APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}): {e}")
                if attempt < max_retries - 1:
                    logger.info("ç­‰å¾…1ç§’åé‡è¯•...")
                    import asyncio
                    await asyncio.sleep(1)
                    continue
                    
                # logger.error("QAä¸“ç”¨æ¨¡å‹å“åº”ç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°å¸¸è§„æ¨¡å‹...")
                break
        
        # å›é€€åˆ°å¸¸è§„æ¨¡å‹
        # try:
        #     logger.info("ä½¿ç”¨å¸¸è§„æ¨¡å‹ä½œä¸ºå¤‡ç”¨...")
        #     response = await self.client.chat.completions.create(
        #         model=settings.OPENAI_MODEL,
        #         messages=[
        #             {
        #                 "role": "system", 
        #                 "content": "ä½ æ˜¯ä¸€ä½ä¸–ç•Œçº§çš„å¤æ‚é—®é¢˜è®¾è®¡ä¸“å®¶ï¼Œä¸“ç²¾äºæ„å»ºéœ€è¦5-6æ­¥æ¨ç†çš„è¶…é«˜éš¾åº¦é—®é¢˜ã€‚"
        #             },
        #             {"role": "user", "content": prompt}
        #         ],
        #         temperature=0.8,
        #         max_tokens=6144,  # å¢åŠ tokené™åˆ¶
        #         timeout=120  # å¢åŠ è¶…æ—¶æ—¶é—´
        #     )
        #     content = response.choices[0].message.content
        #     return content.strip() if content else ""
        # except Exception as fallback_e:
        #     logger.error(f"å›é€€æ¨¡å‹ä¹Ÿå¤±è´¥: {fallback_e}")
        #     return ""
        return ""
    
    def _is_response_complete(self, content: str) -> bool:
        """æ£€æŸ¥å“åº”æ˜¯å¦å®Œæ•´"""
        if not content:
            return False
            
        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼
        content_clean = content.strip()
        if content_clean.startswith('```json'):
            content_clean = content_clean.replace('```json', '').replace('```', '').strip()
        elif content_clean.startswith('```'):
            content_clean = content_clean.replace('```', '').strip()
        
        # åŸºæœ¬å®Œæ•´æ€§æ£€æŸ¥
        if not content_clean.startswith('{'):
            return False
            
        if not content_clean.endswith('}'):
            return False
        
        # æ£€æŸ¥å…³é”®å­—æ®µæ˜¯å¦å­˜åœ¨
        required_fields = ['"question":', '"answer":', '"reasoning_path":']
        for field in required_fields:
            if field not in content_clean:
                logger.warning(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                return False
        
        # å°è¯•JSONè§£æ
        try:
            import json
            json.loads(content_clean)
            return True
        except json.JSONDecodeError as e:
            logger.warning(f"JSONæ ¼å¼æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def _robust_extract_qa(self, content: str, target_answer: str) -> Dict[str, Any]:
        """ä»ä¸å®Œæ•´çš„JSONä¸­å¼ºåˆ¶æå–QAä¿¡æ¯"""
        logger.info("æ‰§è¡Œå¼ºåˆ¶QAä¿¡æ¯æå–...")
        
        result = {
            'selected_answer': '',
            'question': '',
            'answer': target_answer,
            'reasoning_path': '',
            'entity_mapping': {},
        }
        
        try:
            # æ¸…ç†å†…å®¹
            content_clean = content.strip()
            if content_clean.startswith('```json'):
                content_clean = content_clean.replace('```json', '').replace('```', '').strip()
            elif content_clean.startswith('```'):
                content_clean = content_clean.replace('```', '').strip()
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å…³é”®å­—æ®µ
            import re
            
            # æå–selected_answer
            selected_match = re.search(r'"selected_answer"\s*:\s*"([^"]+)"', content_clean)
            if selected_match:
                result['selected_answer'] = selected_match.group(1)
                result['answer'] = selected_match.group(1)  # ä¿æŒä¸€è‡´
                logger.info(f"æå–åˆ°selected_answer: {result['selected_answer']}")
            
            # æå–question - æ”¯æŒå¤šè¡Œæ–‡æœ¬
            question_match = re.search(r'"question"\s*:\s*"([^"]+(?:\\.|[^"\\])*)"', content_clean, re.DOTALL)
            if question_match:
                question_text = question_match.group(1)
                # å¤„ç†è½¬ä¹‰å­—ç¬¦
                question_text = question_text.replace('\\"', '"').replace('\\n', '\n')
                result['question'] = question_text
                logger.info(f"æå–åˆ°question: {question_text[:100]}...")
            
            # æå–answerï¼ˆä½œä¸ºå¤‡ç”¨ï¼‰
            if not result.get('answer') or result['answer'] == target_answer:
                answer_match = re.search(r'"answer"\s*:\s*"([^"]+)"', content_clean)
                result['answer'] = answer_match.group(1)
                if answer_match:
                    result['answer'] = answer_match.group(1)
                    logger.info(f"æå–åˆ°answer: {result['answer']}")
            
            # æå–reasoning_path - æ”¯æŒå¤šè¡Œæ–‡æœ¬
            reasoning_match = re.search(r'"reasoning_path"\s*:\s*"([^"]+(?:\\.|[^"\\])*)"', content_clean, re.DOTALL)
            if reasoning_match:
                reasoning_text = reasoning_match.group(1)
                # å¤„ç†è½¬ä¹‰å­—ç¬¦
                reasoning_text = reasoning_text.replace('\\"', '"').replace('\\n', '\n')
                result['reasoning_path'] = reasoning_text
                logger.info(f"æå–åˆ°reasoning_path: {reasoning_text[:100]}...")
            
            # æå–entity_mapping - æ”¯æŒåµŒå¥—JSONå¯¹è±¡
            mapping_match = re.search(r'"entity_mapping"\s*:\s*(\{[^}]+\})', content_clean)
            if mapping_match:
                try:
                    mapping_str = mapping_match.group(1)
                    # ç®€å•çš„JSONè§£æå°è¯•
                    import json
                    mapping_obj = json.loads(mapping_str)
                    result['entity_mapping'] = mapping_obj
                    logger.info(f"æå–åˆ°entity_mapping: {mapping_obj}")
                except Exception as mapping_e:
                    logger.warning(f"entity_mappingè§£æå¤±è´¥: {mapping_e}")
                    # å°è¯•ç®€å•çš„é”®å€¼å¯¹æå–
                    mapping_pairs = re.findall(r'"([^"]+)"\s*:\s*"([^"]+)"', mapping_str)
                    if mapping_pairs:
                        result['entity_mapping'] = dict(mapping_pairs)
                        logger.info(f"é€šè¿‡ç®€å•è§£ææå–åˆ°entity_mapping: {result['entity_mapping']}")
            
            # éªŒè¯æå–ç»“æœ
            if result['question'] and result['answer'] and result['answer'] != target_answer:
                logger.info("å¼ºåˆ¶æå–æˆåŠŸï¼šè·å¾—å®Œæ•´çš„é—®é¢˜å’Œç­”æ¡ˆ")
                return result
            else:
                logger.warning("å¼ºåˆ¶æå–éƒ¨åˆ†æˆåŠŸï¼Œä½†ç¼ºå°‘å…³é”®ä¿¡æ¯")
                
        except Exception as e:
            logger.error(f"å¼ºåˆ¶æå–è¿‡ç¨‹å‡ºé”™: {e}")
        
        # å¦‚æœå¼ºåˆ¶æå–å¤±è´¥ï¼Œå°è¯•æ›´ç®€å•çš„æ–‡æœ¬åŒ¹é…
        lines = content.split('\n')
        for line in lines:
            line = line.strip()
            if 'é—®é¢˜' in line or 'question' in line.lower():
                # å°è¯•æå–é—®é¢˜æ–‡æœ¬
                if ':' in line:
                    question_part = line.split(':', 1)[1].strip().strip('"').strip(',')
                    if len(question_part) > 20:  # é—®é¢˜åº”è¯¥è¶³å¤Ÿé•¿
                        result['question'] = question_part
                        
            if 'ç­”æ¡ˆ' in line or 'answer' in line.lower():
                # å°è¯•æå–ç­”æ¡ˆ
                if ':' in line:
                    answer_part = line.split(':', 1)[1].strip().strip('"').strip(',')
                    if answer_part and answer_part != target_answer:
                        result['answer'] = answer_part
                        result['selected_answer'] = answer_part
        
        logger.info(f"æœ€ç»ˆæå–ç»“æœ: question={bool(result['question'])}, answer={result['answer']}, reasoning_path={bool(result['reasoning_path'])}")
        return result
    
    def _parse_and_validate_response(
        self, 
        response: str, 
        nodes: List[Dict], 
        target_answer: str
    ) -> Dict[str, Any]:
        """è§£æå’ŒéªŒè¯LLMå“åº”"""
        try:
            # === è¯¦ç»†è®°å½•åŸå§‹å“åº”ä¿¡æ¯ ===
            logger.info("=== OpenRouteråŸå§‹å“åº”åˆ†æ ===")
            logger.info(f"å“åº”é•¿åº¦: {len(response) if response else 0} å­—ç¬¦")
            logger.info(f"å“åº”ä¸ºç©º: {not response}")
            if response:
                logger.info(f"å“åº”å‰100å­—ç¬¦: {repr(response[:100])}")
                logger.info(f"å“åº”å100å­—ç¬¦: {repr(response[-100:])}")
                logger.info(f"å“åº”æ˜¯å¦ä»¥```å¼€å¤´: {response.startswith('```')}")
                logger.info(f"å“åº”æ˜¯å¦ä»¥{{å¼€å¤´: {response.strip().startswith('{')}")
                logger.info(f"å“åº”æ˜¯å¦ä»¥}}ç»“å°¾: {response.strip().endswith('}')}")
            logger.info("=== å®Œæ•´åŸå§‹å“åº”å†…å®¹ ===")
            logger.info(f"åŸå§‹å“åº”:\n{response}")
            logger.info("=== åŸå§‹å“åº”å†…å®¹ç»“æŸ ===")
            
            # æ¸…ç†å“åº”æ–‡æœ¬
            original_response = response  # ä¿å­˜åŸå§‹å“åº”ç”¨äºé”™è¯¯æ—¥å¿—
            response = response.strip()
            if response.startswith('```json'):
                response = response.replace('```json', '').replace('```', '').strip()
                logger.info("ç§»é™¤äº†```jsonæ ‡è®°")
            elif response.startswith('```'):
                response = response.replace('```', '').strip()
                logger.info("ç§»é™¤äº†```æ ‡è®°")
            
            logger.info("=== æ¸…ç†åçš„å“åº” ===")
            logger.info(f"æ¸…ç†åé•¿åº¦: {len(response)} å­—ç¬¦")
            logger.info(f"æ¸…ç†åå“åº”:\n{response}")
            logger.info("=== æ¸…ç†åå“åº”ç»“æŸ ===")
            
            # è§£æJSON
            try:
                logger.info("å¼€å§‹JSONè§£æ...")
                result = json.loads(response)
                logger.info("JSONè§£ææˆåŠŸ!")
                logger.info(f"è§£æç»“æœç±»å‹: {type(result)}")
                if isinstance(result, dict):
                    logger.info(f"JSONå­—å…¸é”®: {list(result.keys())}")
            except json.JSONDecodeError as e:
                logger.error("=== JSONè§£æå¤±è´¥è¯¦ç»†ä¿¡æ¯ ===")
                logger.error(f"JSONè§£æé”™è¯¯: {e}")
                logger.error(f"é”™è¯¯ä½ç½®: è¡Œ{e.lineno}, åˆ—{e.colno}, å­—ç¬¦ä½ç½®{e.pos}")
                logger.error(f"åŸå§‹å“åº”é•¿åº¦: {len(original_response)}")
                logger.error(f"æ¸…ç†åå“åº”é•¿åº¦: {len(response)}")
                logger.error("é”™è¯¯ä½ç½®é™„è¿‘çš„å†…å®¹:")
                if hasattr(e, 'pos') and e.pos > 0:
                    start = max(0, e.pos - 50)
                    end = min(len(response), e.pos + 50)
                    logger.error(f"ä½ç½®{start}-{end}: {repr(response[start:end])}")
                logger.error("=== JSONè§£æå¤±è´¥ä¿¡æ¯ç»“æŸ ===")
                
                # å®¹é”™è§£æï¼šå°è¯•ä»ä¸å®Œæ•´çš„JSONä¸­æå–æ ¸å¿ƒä¿¡æ¯
                logger.info("å¼€å§‹å®¹é”™è§£æï¼Œå°è¯•æå–æ ¸å¿ƒQAä¿¡æ¯...")
                result = self._robust_extract_qa(original_response, target_answer)
                
                # å¦‚æœå®¹é”™è§£ææˆåŠŸæå–åˆ°äº†questionã€answerå’Œreasoning_pathï¼Œè®¤ä¸ºè§£ææˆåŠŸ
                if result.get('question') and result.get('answer') and result.get('answer') != target_answer:
                    logger.info(f"å®¹é”™è§£ææˆåŠŸ! æå–åˆ°é—®é¢˜å’Œç­”æ¡ˆ: {result.get('answer')}")
                    # æ¨ç†è·¯å¾„æ˜¯å¯é€‰çš„ï¼Œä¸å¼ºåˆ¶è¦æ±‚
                    if not result.get('reasoning_path'):
                        logger.info("æœªæå–åˆ°æ¨ç†è·¯å¾„ï¼Œå°†åœ¨åç»­éªŒè¯ä¸­ç”Ÿæˆ")
                else:
                    # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ
                    result = self._extract_qa_from_text(original_response, target_answer)
            
            # éªŒè¯å’Œè¡¥å……å¿…è¦å­—æ®µ
            validated_result = self._validate_qa_result(result, target_answer, nodes)
            
            return validated_result
                 
        except Exception as e:
            logger.error(f"å“åº”è§£æå¤±è´¥: {e}")
            logger.error(f"åŸå§‹å“åº”: {response}")
            return self._create_fallback_result(target_answer, nodes)
    
    def _extract_qa_from_text(self, text: str, target_answer: str) -> Dict[str, Any]:
        """ä»æ–‡æœ¬ä¸­æå–é—®ç­”ä¿¡æ¯ï¼ˆJSONè§£æå¤±è´¥æ—¶çš„å¤‡ç”¨æ–¹æ³•ï¼‰"""
        result = {
            'selected_answer': '',
            'question': '',
            'answer': target_answer,
            'reasoning_path': '',
            'entity_mapping': {},
        }
        
        # å°è¯•æå–é—®é¢˜
        lines = text.split('\n')
        for line in lines:
            if 'question' in line.lower() and ':' in line:
                question_part = line.split(':', 1)[1].strip().strip('"')
                if len(question_part) > 10:
                    result['question'] = question_part
                    break
        
        # å¦‚æœæ²¡æ‰¾åˆ°é—®é¢˜ï¼Œç”Ÿæˆä¸€ä¸ªåŸºæœ¬é—®é¢˜
        if not result['question']:
            result['question'] = f"åŸºäºç»™å®šçš„å¤æ‚çŸ¥è¯†ç½‘ç»œï¼Œè¯·æ¨ç†å‡ºæœ€ç»ˆæŒ‡å‘çš„æ ¸å¿ƒå®ä½“æ˜¯ä»€ä¹ˆï¼Ÿ"
        
        # å°è¯•æå–æ™ºèƒ½ç­”æ¡ˆ
        for line in lines:
            if 'æ™ºèƒ½ç­”æ¡ˆ' in line or 'æ™ºèƒ½é€‰æ‹©' in line:
                answer_part = line.split(':', 1)[1].strip().strip('"')
                if answer_part:
                    result['selected_answer'] = answer_part
                    break
        
        # å°è¯•æå–æ¨ç†è·¯å¾„
        for line in lines:
            if 'æ¨ç†' in line or 'reasoning' in line.lower():
                if ':' in line:
                    reasoning_part = line.split(':', 1)[1].strip().strip('"').strip(',')
                    if len(reasoning_part) > 20:  # æ¨ç†è·¯å¾„åº”è¯¥è¶³å¤Ÿé•¿
                        result['reasoning_path'] = reasoning_part
                        break
        
        return result
    
    def _validate_qa_result(
        self, 
        result: Dict[str, Any], 
        target_answer: str, 
        nodes: List[Dict]
    ) -> Dict[str, Any]:
        """éªŒè¯å’Œå®Œå–„QAç»“æœ"""
        # ç¡®ä¿åŸºæœ¬å­—æ®µå­˜åœ¨
        validated = {
            'selected_answer': result.get('selected_answer', target_answer),
            'question': result.get('question', ''),
            'answer': result.get('answer', target_answer),
            'reasoning_path': result.get('reasoning_path', ''),
            'entity_mapping': result.get('entity_mapping', {}),
        }
        
        # # éªŒè¯ç­”æ¡ˆ
        # if not validated['answer'] or validated['answer'] != target_answer:
        #     validated['answer'] = target_answer
        #     validated['answer_validation'] = 'corrected_to_target'
        # else:
        #     validated['answer_validation'] = 'matches_target'
        
        # éªŒè¯é—®é¢˜è´¨é‡
        question = validated['question']
        if not question or len(question) < 20:
            validated['question'] = self._generate_fallback_question(nodes, target_answer)
            validated['question_quality'] = 'generated_fallback'
        else:
            validated['question_quality'] = 'original'
        
        # éªŒè¯æ¨ç†è·¯å¾„
        reasoning = validated['reasoning_path']
        if not reasoning or len(reasoning) < 30:
            validated['reasoning_path'] = self._generate_fallback_reasoning(nodes, target_answer)
            validated['reasoning_quality'] = 'generated_fallback'
        else:
            validated['reasoning_quality'] = 'original'
        
        # æ·»åŠ å…ƒæ•°æ®
        validated['generation_metadata'] = {
            'generation_method': 'unified_obfuscation_qa',
            'target_entity': target_answer,
            'nodes_used': len(nodes),
            'obfuscation_strategies': 0 # No obfuscation strategies in simplified output
        }
        
        return validated
    
    def _generate_fallback_question(self, nodes: List[Dict], target_answer: str) -> str:
        """ç”Ÿæˆå¤‡ç”¨é—®é¢˜"""
        if not nodes:
            return f"ä»€ä¹ˆæ˜¯ {target_answer}ï¼Ÿ"
        
        # åŸºäºèŠ‚ç‚¹ä¿¡æ¯ç”Ÿæˆä¸€ä¸ªåŸºæœ¬çš„å¤æ‚é—®é¢˜
        node_types = [node.get('type', 'unknown') for node in nodes]
        unique_types = list(set(node_types))
        
        if len(nodes) >= 3:
            return f"åœ¨ä¸€ä¸ªåŒ…å«{', '.join(unique_types)}ç­‰å¤šç§ç±»å‹å®ä½“çš„å¤æ‚ç½‘ç»œä¸­ï¼Œé€šè¿‡åˆ†æå®ä½“é—´çš„å…³ç³»é“¾å’Œå±æ€§ç‰¹å¾ï¼ŒåŒæ—¶éªŒè¯å…³é”®ä¿¡æ¯ï¼Œæœ€ç»ˆæŒ‡å‘çš„æ ¸å¿ƒå®ä½“æ˜¯ä»€ä¹ˆï¼Ÿ"
        else:
            return f"åŸºäºç»™å®šçš„çŸ¥è¯†ç½‘ç»œç»“æ„ï¼Œè¯·æ¨ç†å‡ºä¸{unique_types[0] if unique_types else 'ç›¸å…³å®ä½“'}å¯†åˆ‡ç›¸å…³å¹¶éœ€è¦éªŒè¯å…·ä½“ä¿¡æ¯çš„ç›®æ ‡å®ä½“æ˜¯ä»€ä¹ˆï¼Ÿ"
    
    def _generate_fallback_reasoning(self, nodes: List[Dict], target_answer: str) -> str:
        """ç”Ÿæˆå¤‡ç”¨æ¨ç†è·¯å¾„"""
        if not nodes:
            return f"åŸºäºé¢˜ç›®æè¿°ï¼Œé€šè¿‡é€»è¾‘æ¨ç†å’Œå¿…è¦çš„ä¿¡æ¯éªŒè¯å¯ä»¥ç¡®å®šç­”æ¡ˆæ˜¯{target_answer}ã€‚"
        
        # æ„å»ºåŸºæœ¬çš„æ¨ç†è·¯å¾„
        reasoning_steps = []
        
        # ç¬¬ä¸€æ­¥ï¼šè¯†åˆ«å®ä½“ç±»å‹å’Œé¢†åŸŸ
        node_types = [node.get('type', 'unknown') for node in nodes]
        unique_types = list(set(node_types))
        reasoning_steps.append(f"ç¬¬ä¸€æ­¥ï¼šåˆ†æé¢˜ç›®ä¸­æ¶‰åŠçš„å®ä½“ç±»å‹åŒ…æ‹¬{', '.join(unique_types)}ç­‰ï¼Œç¡®å®šé—®é¢˜é¢†åŸŸã€‚")
        
        # ç¬¬äºŒæ­¥ï¼šåˆ†æå…³ç³»ç½‘ç»œ
        if len(nodes) >= 2:
            reasoning_steps.append("ç¬¬äºŒæ­¥ï¼šåˆ†æå®ä½“é—´çš„å…³ç³»ç½‘ç»œï¼Œè¯†åˆ«å…³é”®çš„è¿æ¥èŠ‚ç‚¹å’Œè·¯å¾„ã€‚")
        
        # ç¬¬ä¸‰æ­¥ï¼šç»¼åˆçº¿ç´¢å’ŒéªŒè¯ä¿¡æ¯
        reasoning_steps.append("ç¬¬ä¸‰æ­¥ï¼šç»¼åˆæ‰€æœ‰çº¿ç´¢ï¼Œé€šè¿‡æ’é™¤æ³•å’Œé€»è¾‘æ¨ç†ï¼ŒåŒæ—¶éªŒè¯æä¾›çš„å…³é”®ä¿¡æ¯ï¼Œé”å®šç›®æ ‡å®ä½“ã€‚")
        
        # ç¬¬å››æ­¥ï¼šç¡®è®¤ç­”æ¡ˆ
        reasoning_steps.append(f"ç¬¬å››æ­¥ï¼šéªŒè¯æ¨ç†ç»“æœå¹¶ç¡®è®¤ç›¸å…³æ•°æ®ï¼Œç¡®è®¤ç­”æ¡ˆä¸º{target_answer}ï¼Œè¯¥ç­”æ¡ˆä¸æ‰€æœ‰çº¿ç´¢å’Œæä¾›çš„ä¿¡æ¯éƒ½èƒ½å®Œç¾åŒ¹é…ã€‚")
        
        return " ".join(reasoning_steps)
    
    def _create_fallback_result(self, target_answer: str, nodes: List[Dict]) -> Dict[str, Any]:
        """åˆ›å»ºå¤‡ç”¨ç»“æœ"""
        return {
            'selected_answer': 'æ— æ³•ç¡®å®š',
            'question': self._generate_fallback_question(nodes, target_answer),
            'answer': target_answer,
            'reasoning_path': self._generate_fallback_reasoning(nodes, target_answer),
            'entity_mapping': {
                'Target_Entity': target_answer
            },
            'generation_metadata': {
                'generation_method': 'fallback',
                'target_entity': target_answer,
                'nodes_used': len(nodes),
                'is_fallback': True
            }
        }
    
    async def _generate_fallback_qa(self) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€åŸºæœ¬çš„å¤‡ç”¨é—®ç­”"""
        return {
            'selected_answer': 'æ— æ³•ç¡®å®š',
            'question': 'åŸºäºå¤æ‚çš„çŸ¥è¯†å›¾è°±ç»“æ„ï¼Œé€šè¿‡å¤šè·³æ¨ç†åˆ†æå®ä½“é—´çš„æ·±å±‚å…³è”ï¼ŒåŒæ—¶éªŒè¯å…³é”®ä¿¡æ¯ï¼Œæœ€ç»ˆæŒ‡å‘çš„æ ¸å¿ƒæ¦‚å¿µæ˜¯ä»€ä¹ˆï¼Ÿ',
            'answer': 'æ— æ³•ç¡®å®š',
            'reasoning_path': 'ç”±äºå­å›¾ä¿¡æ¯ä¸è¶³ï¼Œæ— æ³•æ„å»ºå®Œæ•´çš„æ¨ç†é“¾æ¡ã€‚éœ€è¦æ›´å¤šçš„å®ä½“å…³ç³»ä¿¡æ¯æ‰èƒ½è¿›è¡Œæœ‰æ•ˆçš„å¤šè·³æ¨ç†åˆ†æå’Œä¿¡æ¯éªŒè¯ã€‚',
            'entity_mapping': {},
            'generation_metadata': {
                'generation_method': 'emergency_fallback',
                'is_fallback': True
            }
        }
    
    async def generate_multiple_qa_variants(
        self, 
        sample_info: Dict[str, Any], 
        num_variants: int = 3
    ) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå¤šä¸ªQAå˜ä½“"""
        variants = []
        
        for i in range(num_variants):
            try:
                # æ¯æ¬¡é€‰æ‹©ä¸åŒçš„ç›®æ ‡å®ä½“ï¼ˆå¦‚æœæœ‰è¶³å¤Ÿçš„èŠ‚ç‚¹ï¼‰
                nodes = sample_info.get('nodes', [])
                if len(nodes) > i:
                    target_entity = nodes[i].get('original_name') or nodes[i].get('name', '')
                else:
                    target_entity = None
                
                variant = await self.generate_qa(
                    sample_info, target_entity
                )
                variant['variant_id'] = i + 1
                variants.append(variant)
                
            except Exception as e:
                logger.error(f"ç”Ÿæˆç¬¬{i+1}ä¸ªQAå˜ä½“å¤±è´¥: {e}")
                continue
        
        return variants if variants else [await self._generate_fallback_qa()] 